{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercise 5**: Model scenario analysis\n",
    "\n",
    "In this exercises we will do a scenario analysis with the model created with notebook 01.\n",
    "We will update the sea level boundary condition to simulate the effect of sea level rise on flood risk in Savannah.\n",
    "You can use this notebook as template to run other scenario analyses to e.g. assess the effect of adaptation measures, land use changes, or future climate conditions.\n",
    "\n",
    "The steps to do so are:\n",
    "- Step 1: Read the model a change the output root folder to a new directory\n",
    "- Step 2: Update the model and save it. This can be the sea level boundary condition, or any other model parameter you want to change.\n",
    "- Step 3: Run the model again\n",
    "- Step 4: Inspect the differences in the results (flood extent, flood depth, etc.)\n",
    "\n",
    "## **Step 0:** Import dependencies\n",
    "\n",
    "Before anything else we need to import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hydromt\n",
    "from hydromt.log import setuplog\n",
    "from hydromt_sfincs import SfincsModel\n",
    "\n",
    "# local script\n",
    "from sfincs_utils import run_sfincs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1:** Read the model a change the output root\n",
    "Now let's copy our old model to a new folder, so we can always look at the old model later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root_old = '..\\models\\sfincs_savannah'\n",
    "model_root_new = '..\\models\\sfincs_savannah_slr'\n",
    "\n",
    "# initialize the old model again with a logger and the data catalog\n",
    "# but now in read-only mode\n",
    "logger = setuplog(\"SFINCS_log_savannah\", log_level=20)\n",
    "sf = SfincsModel(root=model_root_old, mode=\"r\", logger=logger)\n",
    "sf.read()\n",
    "\n",
    "# change the model root (to not overwrite existing model)\n",
    "# it is recommended to use a different root_folder for each model run\n",
    "# make sure to keep your folders well organized\n",
    "# NOTE that this does not copy any data, it just points to a new location where the model will be saved later\n",
    "sf.set_root(model_root_new, mode=\"w+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2:** Update forcing\n",
    "\n",
    "Now we will update the forcing of the model. We will use the same forcing as in the previous exercise, but will now add an offset to the water levels to simulate sea level rise.\n",
    "\n",
    "Note that the index attribute of the locations matches with the column names of the timeseries file. This is important for HydroMT to know which timeseries belongs to which location!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read  location\n",
    "locations = gpd.read_file(\n",
    "    Path(r\"../data/gtsm_codec_reanalysis_hourly_v1/gauging_location.geojson\")\n",
    ")\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read design hydrographs\n",
    "timeseries = pd.read_csv(\n",
    "    Path(r\"../data/gtsm_codec_reanalysis_hourly_v1/timeseries_Irma_2.csv\"),\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    ")\n",
    "# clip to model event period\n",
    "tstart, tstop = sf.get_model_time()\n",
    "timeseries = timeseries.loc[tstart:tstop]\n",
    "timeseries.iloc[[0, 1, -2, -1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the sea level rise in 2100\n",
    "# hint use the IPCC AR6 interactive atlas via https://interactive-atlas.ipcc.ch/regional-information\n",
    "# select the right variable, period en scenario, then click on the region of interest to get the a graph or table from which you can estimate the sea level rise\n",
    "slr = 1 # [m] FILL IN YOUR ESTIMATE HERE\n",
    "\n",
    "timeseries_slr = timeseries.copy()\n",
    "# change the event period to 2100\n",
    "timeseries_slr.index = (\n",
    "    timeseries.index - timeseries.index[0] + pd.Timestamp(\"2100-01-01\")\n",
    ")\n",
    "# add sea level rise to the timeseries\n",
    "timeseries_slr = timeseries_slr + slr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to update the model event time to the new period\n",
    "# which we can do based on the timeseries index\n",
    "sf.setup_config(\n",
    "    tref=timeseries_slr.index[0].to_pydatetime(),\n",
    "    tstart=timeseries_slr.index[0].to_pydatetime(),\n",
    "    tstop=timeseries_slr.index[-1].to_pydatetime(),\n",
    ")\n",
    "\n",
    "# this time we provide the locations and timeseries as\n",
    "# pandas / geopandas objects instead of the data catalog keys\n",
    "sf.setup_waterlevel_forcing(\n",
    "    locations=locations,\n",
    "    timeseries=timeseries_slr,\n",
    "    merge=False,\n",
    "    # use a large buffer to include all points if the following error is raised\n",
    "    # ValueError: The gdf_locs index and df_ts columns must be the same\n",
    "    buffer=1e5,  # buffer from model boundary [m]\n",
    ")\n",
    "\n",
    "sf.plot_forcing(\"forcing.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model after updating the forcing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to write the updated model to the new model root before running sfincs\n",
    "sf.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3:** Rerun the model, using the new boundary conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE you need to download the SFINCS executable first (see first notebook) and update the path below\n",
    "sfincs_exe = \"../software/sfincs_v2.1.1/sfincs_exe\"\n",
    "run_sfincs(\n",
    "    Path(sf.root, \"sfincs.inp\"), # path to the SFINCS model root folder\n",
    "    run_method=\"exe\", # run SFINCS using the executable, other options are \"docker\" or \"singularity\"\n",
    "    sfincs_exe=sfincs_exe, # path to the sfincs executable if you want to run SFINCS on windows\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4:** Inspecting the results: floodmap\n",
    "\n",
    "Inspect the results of the updated model run by plotting the maximum water depths on a map. \n",
    "In order to do so you should first read the results of the model (*sf.read_results()*). After this you can access the results by using the results attribute: *sf.results*.\n",
    "The results you can plot using matplotlib.\n",
    "\n",
    "*Tip: Print all available result keys by typing `print(sf.results.keys())`*  \n",
    "*Tip:* You can also plot the results on top of the SFINCS basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hmax is computed by SFINCS and read-in from the sfincs_map.nc file\n",
    "sf.read_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the subgrid resolution topography to downscale the maximum water level to water depth at the subgrid resolution\n",
    "# First, we read the subgrid resolution topography and check if the file exists\n",
    "dep_subgrid_file = Path(model_root_old, \"subgrid\", \"dep_subgrid.tif\")  \n",
    "if not dep_subgrid_file.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Subgrid resolution topography file not found: {dep_subgrid_file}. \"\n",
    "    )\n",
    "dep_subgrid = hydromt.open_raster(dep_subgrid_file, nodata=np.nan) # elevation at subgrid resolution\n",
    "\n",
    "# calculate the maximum water depth (hmax) as the difference between \n",
    "# the maximum water level (zsmax) and the elevation (dep)\n",
    "zsmax = sf.results[\"zsmax\"].max(dim=\"timemax\") # maximum water level\n",
    "zsmax_subgrid = zsmax.raster.reproject_like(dep_subgrid, method=\"nearest\")  # reproject to subgrid resolution\n",
    "hmax_subgrid = np.maximum(0, zsmax_subgrid - dep_subgrid).round(2).astype(np.float32) # maximum water depth\n",
    "# Here, we assume that all areas with a negative depth are permanent water bodies\n",
    "# This is a strong simplification. It is better to use a more sophisticated approach\n",
    "# to identify permanent water bodies, e.g. based on a water mask or a \"tide-only\" simulation.\n",
    "permament_water = dep_subgrid < 0 \n",
    "hmax_subgrid = hmax_subgrid.where(~permament_water, np.nan) # mask areas with permanent water\n",
    "# update (geospatial) metadata\n",
    "hmax_subgrid.raster.set_crs(dep_subgrid.raster.crs)\n",
    "hmax_subgrid.raster.set_nodata(np.nan)\n",
    "hmax_subgrid.name = \"max water depth\"\n",
    "hmax_subgrid.attrs[\"units\"] = \"m\"\n",
    "\n",
    "fig, ax = sf.plot_basemap(\n",
    "    fn_out=\"hmax.png\",  # save figure to mod.root/figs/hmax.png\n",
    "    variable=hmax_subgrid,\n",
    "    plot_bounds=False,\n",
    "    bmap=\"sat\",\n",
    "    zoomlevel=12,\n",
    "    figsize=(11, 7),\n",
    "    vmin=0,  # set minimum value for colorbar\n",
    "    vmax=3,  # set maximum value for colorbar\n",
    "    cmap=\"BuPu\",\n",
    ")\n",
    "ax.set_title(\"SFINCS maximum water depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a geotiff file\n",
    "# round to 2 decimals to reduce file size\n",
    "\n",
    "hmax_subgrid.raster.set_nodata(np.nan)\n",
    "hmax_subgrid.round(2).raster.to_raster(\n",
    "    Path(sf.root, f\"hmax_slr{int(slr*100)}.tif\"),\n",
    "    compress=\"lzw\",\n",
    "    overwrite=True,\n",
    "    dtype=\"float32\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the original maximum water depth and create a difference map\n",
    "# adapt and complete the code below\n",
    "\n",
    "hmax_org_file = Path(model_root_old, \"hmax.tif\")\n",
    "hmax_org = hydromt.open_raster(hmax_org_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5b: Adaptation measure scenario analysis\n",
    "\n",
    "Implement the same for other scenario analyses, e.g. by implementing an adaptation measure such as a levee or floodwall.\n",
    "\n",
    "You can do this by implementing a [weir structure](https://sfincs.readthedocs.io/en/latest/input_structures.html#weirs) in the model.\n",
    "\n",
    "This is done by drawing a line geometry file in e.g. QGIS or geojson.io of the levee/floodwall location. Each line should have a height \"z\" attribute value which defines the crest height. The weir can then be added to the model using the HydroMT-SFINCS method [setup_structures()](https://deltares.github.io/hydromt_sfincs/stable/_generated/hydromt_sfincs.SfincsModel.setup_structures.html#hydromt_sfincs.SfincsModel.setup_structures)\n",
    "\n",
    "We suggest you make a copy of the notebook and implement the changes there following the steps as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "integrated-modelling-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
