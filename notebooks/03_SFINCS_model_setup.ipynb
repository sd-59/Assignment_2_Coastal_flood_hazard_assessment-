{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exercise 3**: Build your own model for Charleston\n",
    "\n",
    "In this exercise we will create our own SFINCS model for the area around Charleston. After doing this exercise you will know how to set up a basic SFINCS model from scratch, how to add forcing to it, run it and visualize the output. \n",
    "\n",
    "We will follow the following steps to create the model:\n",
    "\n",
    "- Introduction: Add data to the HydroMT datacatalog\n",
    "- Step 1: Setup the model domain\n",
    "- Step 2: Initialize and define the model grid\n",
    "- Step 3: Interpolate elevation data to the model grid\n",
    "- Step 4: Set model active and boundary cells\n",
    "- Step 5: Setup subgrid tables\n",
    "- Step 6: Add forcing to the model\n",
    "- Step 7: (Optional) Add observation (output) points\n",
    "- Step 8: Save the model (and create zip archive)\n",
    "- Step 9: Running the model\n",
    "- Step 10: Visualize the output data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data used\n",
    " - Model domain:\n",
    "    - self-defined polygons\n",
    " - Topography & Bathymetry:\n",
    "    - GEBCO bathymetry\n",
    "    - Local DEM for Charleston (10m resolution)\n",
    " - Waterlevels:\n",
    "    - GTSM\n",
    " - Manning roughness:\n",
    "    - ESA worldcover (land cover)\n",
    "    - A reclassification table (reclassify land covert to manning roughness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies\n",
    "\n",
    "Before anything else we need to import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import geopandas as gpd\n",
    "import hydromt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hydromt.log import setuplog\n",
    "from hydromt_sfincs import SfincsModel\n",
    "\n",
    "# local script imports\n",
    "from sfincs_utils import run_sfincs, create_sfincs_model_archive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: The hydroMT data catalog\n",
    "\n",
    "HydroMT uses a data catalog to access and uniformize your data. A data catalog is a *.yml* file with references to external datasets, their metadata, together with some optional basic preprocessing, so the data is already in the correct format when loading it into python. Examples of preprocessing steps are are: renaming of variables, unit conversion using offsets and multiplication, setting missing nodata and CRS metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this course we have prepared the `\"../data/data_catalog.yml\"` file which references most data in the data folder, except for the local DEM file \"topography_charleston_10m.tif\". You can add this data by manually modifying the data catalog by editing the .yml file in a text editor such as VSCode or Notepad++ which have visual support for yml files. \n",
    "\n",
    "See the HydroMT documentation for more information on how to [prepare a data catalog](https://deltares.github.io/hydromt/v0.10.0/user_guide/data_prepare_cat.html) and [how to add a raster dataset](https://deltares.github.io/hydromt/v0.10.0/user_guide/data_types.html#rasterdataset). \n",
    "**NOTE**: make sure to use the version of the documentation matching your HydroMT installed version (likely v0.10) \n",
    "\n",
    "In short the steps to update the data catalog are:\n",
    "- Open the ../data/data_catalog.yml file and look at the different entries. Note the different data types and drivers (i.e. methods to read the data)\n",
    "- Now create a new data catalog key called `topography_charleston`, you can copy one of the other keys that are already present, e.g. the `gebco` one\n",
    "- Navigate to the `../data` folder and change the path of your data to the correct file\n",
    "- Also change the CRS to the correct coordinate reference system or leave it empty if it is contained in the file metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the data catalog with to include the local DEM file and uncomment the following line\n",
    "# data_catalog_file = \"../data/data_catalog.yml\"\n",
    "data_catalog = hydromt.data_catalog.DataCatalog(data_catalog_file)\n",
    "\n",
    "# view the data catalog, make sure the DEM is included\n",
    "data_catalog.to_dataframe()[\n",
    "    [\"path\", \"data_type\", \"driver\", \"source_url\", \"source_version\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1:** Setup model domain\n",
    "\n",
    "The first step of building a model is to specify the area we're interested in and turn this into the model domain.\n",
    "The area of interest is best specified through a geojson file. An example is given at `../model_domain/model_domain.geojson`. \n",
    "A useful tool to draw your own geojson file is http://geojson.io or QGIS. \n",
    "\n",
    "Note that when including rainfall as flood driver you need to make sure that the watersheds contributing to pluvial flooding \n",
    "are completely within your model domain to make sure you capture all rainfall. In that case it is best to use shapefiles\n",
    "of hydrological basins to guide your model domain delineation. In the data catalog the HydroSheds basin atlas is included\n",
    "for the region of Charleston and can be used for this purpose. Here, we are focused on coastal flooding only and hence \n",
    "can be more relaxed about the inland boundary location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a (relative) path to the model domain geojson file.\n",
    "# This file should contain the region of interest for the model.\n",
    "# An example file is provided in the \"../model_domain\" folder.\n",
    "# region_fn = Path(..)\n",
    "\n",
    "# Load in our initial region of interest using geopandas\n",
    "region = gpd.read_file(region_fn).to_crs(epsg=4326)\n",
    "\n",
    "# Plot the region of interest\n",
    "fig, ax = plt.subplots(figsize=(6, 6), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "ax.add_image(cimgt.OSM(), 10)\n",
    "region.boundary.plot(ax=ax, color=\"red\", label=\"Model Domain\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 2:** Initialize and define the model grid\n",
    "\n",
    "Now that we determined where to make a model, we can initialize and build our model.\n",
    "\n",
    "When initializing the model, we can specify the following:\n",
    " - `root`: Folder where the model is to be saved. Path is relative to current working directory\n",
    " - `mode`: Whether you want to read/append/write the model (to prevent overwriting a model by accident)\n",
    " - `data_libs`: One or multiple data catalogs.\n",
    " - `logger`: The name of the logger used to keep track of changes to the model\n",
    "\n",
    "If a model already exists in the root location we override it by initializing our new model in 'w+' mode. Note that we also add our data catalog to the model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify root_folder and logger_name\n",
    "# The root_folder is where the model will be stored, use a subfolder of the \"../models\" folder\n",
    "root_folder = Path(r\"../models/sfincs_charleston\")\n",
    "logger_name = \"SFINCS_log_charleston\"\n",
    "logger = setuplog(\n",
    "    logger_name, log_level=20\n",
    ")  # log_level=20 is INFO, more messages are shown with log_level=10 (DEBUG)\n",
    "\n",
    "# initialize model\n",
    "sf = SfincsModel(\n",
    "    root=root_folder,\n",
    "    mode=\"w+\",  # overwrite mode\n",
    "    data_libs=[data_catalog_file],\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a model grid by providing our domain and the grid resolution in units given by the crs. By specifying crs=\"utm\", the closest UTM-zone will be used for your model. Any geometries specified in a CRS different than the model CRS will be converted automatically.\n",
    "\n",
    "Initially the grid will be a rectangle around the provided domain. Later on we will refine this by defining the active cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHOOSE YOUR MODEL RESOLUTION in the units of the projection (crs)\n",
    "# We suggest to use a relatively coarse resolution for sake of the tutorial\n",
    "# model_res = <SET MODEL RES> # in meters if model_crs is 'utm'\n",
    "\n",
    "# we setup the grid based on the bounding box of the region\n",
    "sf.setup_grid_from_region(\n",
    "    region={\"geom\": region_fn},\n",
    "    res=model_res,\n",
    "    rotated=False,  # non-rotated grid.\n",
    "    crs=\"utm\",  # automatically the closest UTM zone is selected (unit is in meters),\n",
    ")\n",
    "\n",
    "# Inspect some grid paramaters:\n",
    "# shape (mmax x nmax), and resolution in both directions (dx,dy)\n",
    "print(\"\\nGRID PARAMETERS\\n\")\n",
    "print(f'shape: {sf.config[\"mmax\"]}, {sf.config[\"nmax\"]}')\n",
    "print(f'resolution: {sf.config[\"dx\"]}, {sf.config[\"dy\"]}')\n",
    "print(f'origin: {sf.config[\"x0\"]}, {sf.config[\"y0\"]}')\n",
    "print(f'rotation: {sf.config[\"rotation\"]}')\n",
    "print(f'crs: EPSG:{sf.config[\"epsg\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "1a) What is the grid resolution?\n",
    "\n",
    "1b) How many cells are there in x & y direction?\n",
    "\n",
    "1c) Is the model rotated?\n",
    "\n",
    "1d) Why are the grid origins (x0 & y0) not in latitude-longitude [degree] units?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in your own answers:\n",
    "\n",
    "1a)\n",
    "\n",
    "1b)\n",
    "\n",
    "1c)\n",
    "\n",
    "1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 3:** Interpolate elevation data to the grid\n",
    "\n",
    "We first interpolate elevation data to the grid using `setup_dep()`. This will help to refine the grid later.\n",
    "Note that this data is not actually used in the model, as we will set up subgrid tables later on which replaces the grid-averaged elevation data.\n",
    "However, having elevation data on the grid is useful to visualize the terrain and to define active cells in the next step.\n",
    "\n",
    "It is possible to provide multiple datasets for the elevation data as we do below. Each subsequent data set will fill in the gaps in the grid. \n",
    "For each dataset, you can optionally set the valid area by providing a minimum or maximum elevation limit `zmin` and `zmax` or geometry `mask`. \n",
    "Furthermore, you can correct for differences in vertical datums between elevation datasets using a uniform or gridded `offset` value which is applied to the dataset.\n",
    "\n",
    "#### Template for elevation data sources\n",
    "\n",
    "The data is provided using the template for the `datasets_dep` input below. \n",
    "Per source, all arguments except for `elevtn` are optional\n",
    "\n",
    "```python\n",
    "datasets_dep = [\n",
    "    {\n",
    "        'elevtn': '<elevation data source name>',  # source 1\n",
    "        'offset': '<offset to vertical datum>',\n",
    "        'zmin': '<minimum valid elevation value>',\n",
    "        'zmax': '<maximum valid elevation value>',\n",
    "    },\n",
    "    {\n",
    "        'elevtn': '<elevation data source name>',  # source 2\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the elevation datasets to use. Note that the names refer to the keys in the data_catalog\n",
    "# The first dataset is used as the primary elevation source\n",
    "# The second dataset is used to fill gaps in the first dataset\n",
    "# charleston_dem_source = ADD YOUR DEM SOURCE HERE\n",
    "datasets_dep = [\n",
    "    {\n",
    "        \"elevtn\": charleston_dem_source\n",
    "    }, \n",
    "    {\n",
    "        \"elevtn\": \"gebco\", \n",
    "        \"zmax\": 0\n",
    "    }\n",
    "]\n",
    "dep = sf.setup_dep(datasets_dep=datasets_dep, buffer_cells=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note the elevation values are stored in the \"dep\" variable of the model grid component.\n",
    "sf.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the elevation on top of the model region and satellite image. The variable argument sets which model variable to plot\n",
    "fig, ax = sf.plot_basemap(variable=\"dep\", bmap=\"sat\")\n",
    "sf.grid.raster.vector_grid(\"lines\").plot(ax=ax, color=\"k\", linewidth=0.1, label=\"grid\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 4:** Set active and boundary cells\n",
    "\n",
    "### Active cells\n",
    "\n",
    "Next, we refine the grid by specifying which cells are active by calling the function `setup_mask_active()`. \n",
    "Active cells are initialized based on a `mask` geometry. \n",
    "\n",
    "Below you are asked to define the active cells for your model in two steps to learn how the arguments work. \n",
    "In the first step you are asked to initialize the active cells based on the region geometry `mask` which you used the initialize the grid.\n",
    "In the second step you can further refine it using additional arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set mask based on mask \n",
    "\n",
    "# Set the mask based on the region mask\n",
    "sf.setup_mask_active(\n",
    "    mask=region_fn,  # Path to the mask file, commonly the region of interest\n",
    "    reset_mask=True,   # Make sure we start with a clean mask\n",
    ")\n",
    "\n",
    "# Plot the mask. Using variable='msk' will display the mask values for the active cells.\n",
    "_ = sf.plot_basemap(variable=\"msk\", bmap=\"sat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improving the mask\n",
    "\n",
    "If you are not satisfied with the initial active mask you created, you can either modify the geometry file you used in e.g. QGIS or use the additional arguments of the `setup_mask_active()` function to refine it as shown below.\n",
    "\n",
    "You can refine your mask using the a minimum `zmin` and maximum height `zmax` arguments.\n",
    "Furthermore, he active cells can be refined by adding areas inside the `include_mask` geometries, or removing areas inside the `exclude_mask` geometries. \n",
    "Small groups of isolated cells can be removed with the `drop_area` argument while holes in the mask can be filled with the `fill_area` argument. \n",
    "If `reset_mask=True` to existing mask is re-initialized and previous edits are overwritten. \n",
    "Be mindful of this setting in case you define active cells with multiple calls of `setup_mask_active()`.\n",
    "\n",
    "You can draw include and exclude geometries in e.g. http://geojson.io or QGIS and export to geojson to use here. \n",
    "If you want draw these geometries on top of the existing mask you can export it to geotiff using `sf.grid[\"msk\"].raster.to_raster(\"path/to/mask.tif\")` and load in QGIS.\n",
    "\n",
    "Find more information about the function `setup_mask_active()` [in the docs](https://deltares.github.io/hydromt_sfincs/stable/_generated/hydromt_sfincs.SfincsModel.setup_mask_active.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include mask and exclude mask polygons:\n",
    "# zmin_active = <ZMIN LEVEL>\n",
    "# zmax_active = <ZMAX LEVEL>\n",
    "# include_mask_filename = Path('../model_domain/YOUR_INCLUDE_MASK')\n",
    "# exclude_mask_filename = Path('../model_domain/YOUR_EXCLUDE_MASK')\n",
    "# drop_area = <YOUR_DROP_AREA>\n",
    "# fill_area = <YOUR_FILL_AREA>\n",
    "\n",
    "# Run function:\n",
    "# comment out a line if you don't use the include mask, exclude mask, drop area or fill area\n",
    "sf.setup_mask_active(\n",
    "    zmin=zmin_active,  # Minimum elevation [m] to set as active\n",
    "    zmax=zmax_active,  # Maximum elevation [m] to set as active\n",
    "    include_mask=include_mask_filename,\n",
    "    exclude_mask=exclude_mask_filename,\n",
    "    drop_area=drop_area,\n",
    "    fill_area=fill_area,\n",
    "    reset_mask=False,  # Make sure we continue with the current mask\n",
    ")\n",
    "\n",
    "# Plot the mask. Using variable='msk' will display the mask values for the active cells.\n",
    "_ = sf.plot_basemap(variable=\"msk\", bmap=\"sat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "2a) Inspect the mask that is created, does is comply with your expectations? \n",
    "\n",
    "2b) How many active cells does your model have? (Tip: take the sum of all mask cells larger than zero using `sf.grid['msk']`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in your own answer:\n",
    "\n",
    "2a)\n",
    "\n",
    "2b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boundary cells\n",
    "\n",
    "The boundaries function by default as hard walls, allowing no flow in or out. We want to use the boundaries on *downstream* open water boundaries to force the water levels there. We can do this by calling `setup_mask_bounds()`. Setting `btype=\"waterlevel\"` will specify waterlevel boundaries (msk=2). Boundary cells can be selected similarly to the active cells, by providing elevation limits `zmax` (i.e. all boundary cells below this elevation will set as waterlevel boundary) and/or using `include_mask` and `exclude_mask`.\n",
    "\n",
    "If you suspect any significant flow to outside the model to occur at some boundaries, you can set those boundaries as outflow boundaries by setting `btype=\"outflow\"` providing the geometry of the desired bounds. This is usually only necessary when applying rainfall to the grit. For stability, avoid outflow boundaries adjacent to waterlevel boundaries.  \n",
    "\n",
    "Find more information about the function `setup_mask_bounds()` [in the docs](https://deltares.github.io/hydromt_sfincs/stable/_generated/hydromt_sfincs.SfincsModel.setup_mask_bounds.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup water level bounds\n",
    "\n",
    "# use either on of the following options:\n",
    "# zmax_bounds = <THE_MAX_WATERLEVEL>\n",
    "# waterlevel_mask_filename = Path('../models/YOUR_WATERLEVEL_MASK')\n",
    "\n",
    "# comment out a line to ignore the argument\n",
    "sf.setup_mask_bounds(\n",
    "    btype=\"waterlevel\",\n",
    "    zmax=zmax_bounds,          # Maximum elevation of boundary cells [m] to assign as waterlevel boundary\n",
    "    include_mask=waterlevel_mask_filename,  # mask of boundary cells to assign as waterlevel boundary\n",
    "    reset_bounds=True,\n",
    ")\n",
    "\n",
    "# Inspect the updated mask. Mask value 2 means waterlevel boundary, mask value 3 means outflow boundary\n",
    "_ = sf.plot_basemap(variable=\"msk\", bmap=\"sat\", plot_bounds=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "a) Does the waterlevel boundary nicely cover coastal boundary of your model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in your answers:\n",
    "\n",
    "3a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 5:** Setup subgrid tables\n",
    "\n",
    "By pre-calculating lookup tables that account for the subgrid variation in bedlevels and friction, the computation can be executed at a courser resolution (i.e. the model grid) without loosing much accuracy up to a certain resolution. \n",
    "The lookup tables contain storage and conveyance capacity levels for (usually ~15) different water levels. \n",
    "At computation the cell storage and conveyance capacity to neighboring cells is estimated by interpolating the information from these tables. \n",
    "The subgrid approach assumes a uniform water level within the entire model grid cell. Hence on steep terrain this assumption might not be valid. \n",
    "\n",
    "The subgrid tables require both the elevation `datasets_dep`, as specified in step 3, and roughness datasets `datasets_rgh` as shown below.\n",
    "Furthermore, the subgrid resolution `nr_subgrid_pixels` needs to be specified as a ratio of the model grid resolution (i.e. 10 means 10x finer subgrid resolution).\n",
    "The number of levels `nlevels` at which the subgrid variation is described can be specified. More levels usually lead to more accurate results, but also increase the model setup time and size of the model files.\n",
    "For the computation of the subgrid tables, the maximum number of subgrid pixels per calculation block `nrmax` needs to be specified. Decrease this value if you run into memory errors during model setup.\n",
    "For other options of the `setup_subgrid()` function see the [docs](https://deltares.github.io/hydromt_sfincs/stable/_generated/hydromt_sfincs.SfincsModel.setup_subgrid.html).\n",
    "\n",
    "Reference paper: https://gmd.copernicus.org/articles/18/843/2025/ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model **surface roughness** data\n",
    "\n",
    "We can specify the surface roughness to better characterize the water flow on open surfaces. When we don't specify anything defaults values for the manning roughness are used based on elevation thresholds. We can specify manning roughness values ourselves, or we can provide a dataset with landuse classes. These classes are then converted to roughness values using a reclassification table. Here, it is also possible to provide multiple datasets to fill in any gaps that might exist in the previous datasets, similar to the elevation. \n",
    "\n",
    "In this example we will use the ESA worldcover land use dataset together with a reclass table which maps each landuse class to a specific manning roughness value, see below how such table should look like. Both are called with the proper entry name from the data catalog. We recommend using more detailed local datasources if those are available. \n",
    "\n",
    "#### example reclass table to map landuse to roughness values (N)\n",
    "| class | description               | N     |\n",
    "|-------|---------------------------|-------|\n",
    "| 10    | Tree cover                | 0.12  |\n",
    "| 20    | Shrubland                 | 0.05  |\n",
    "| 30    | Grasland                  | 0.034 |\n",
    "| ..    | ........                  | ..... |\n",
    "| 0     | No data                   | -999  |\n",
    "\n",
    "#### Template for roughness data sources\n",
    "\n",
    "The data is provided using the template for the `datasets_rgh` input below. \n",
    "Per source, the `lulc` and `reclass_table` fields are required.\n",
    "\n",
    "```python\n",
    "datasets_rgh = [\n",
    "    {\n",
    "        \"lulc\": <landuse/landcover source name>,  # source 1\n",
    "        \"reclass_table\": <reclassification table source name>,  \n",
    "    },\n",
    "    {\n",
    "        \"lulc\": <landuse/landcover source name>,  # source 2\n",
    "        \"reclass_table\": <reclassification table source name>,  \n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the surface roughness datasets to use. Note that the names refer to the keys in the data_catalog\n",
    "# Here we use the ESA worldcover landuse dataset together with a reclass table which maps each landuse class to a specific manning roughness value\n",
    "datasets_rgh = [\n",
    "    {\n",
    "        \"lulc\": \"esa_worldcover\",  # landuse/landcover dataset\n",
    "        \"reclass_table\": \"esa_worldcover_mapping\",  # reclassification table\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model subgrid elevation\n",
    "\n",
    "See step 3 for defining elevation data sources. You may use the same elevation datasets as in step 3 or different ones if you have higher resolution data available for your model domain.\n",
    "In case of the latter, redefine the `datasets_dep` variable accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the subgrid resolution as a ratio of the model grid (i.e. 10 means 10x finer subgrid resolution)\n",
    "# select a value that is appropriate based on your model grid resolution and the resolution of the available high resolution topography data\n",
    "# To avoid running into memory errors, for this course we advise to use a subgrid resolution of at least 10 meters. \n",
    "# nr_subgrid_pixels = <SET SUBGRID RESOLUTION>\n",
    "\n",
    "# NOTE: this step can take some time (~minutes)\n",
    "sf.setup_subgrid(\n",
    "    datasets_dep=datasets_dep,  # elevation datasets, same as step 3\n",
    "    datasets_rgh=datasets_rgh,  # roughness datasets, same as step 4\n",
    "    nlevels=15,  # number of levels at which the subgrid variotion is described\n",
    "    nr_subgrid_pixels=nr_subgrid_pixels,  # subgrid resolution as ratio of model grid (i.e. 10 means 10x finer subgrid resolution)\n",
    "    nrmax=4000,  # maximum number of subgrid pixels per calculation block (decrease if memory errors occur)\n",
    "    write_dep_tif=True,  # write subgrid elevation to tif\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "a) What is the subgrid pixel resolution? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 6:** Add Forcing\n",
    "\n",
    "Next we configure the forcing, the data we use as input in the model. SFINCS forcings include water levels at the waterlevel boundaries, river discharges at source points, rainfall, wind and pressure. For this example where we simulate coastal flooding, we only use water level boundaries. First, we need to set a time window to simulate. In subsequent steps to setup the forcing data will only be saved for this time period. \n",
    "\n",
    "Look on the internet when a large flood event happened in Charleston in 2016 (we only have forcing data for October 2016 prepared) and use this event for your model by setting the start time `tstart` and end time `tend`, the reference time `tref` is usually also set to the start time. 2 days of simulation around the event should be sufficient. In addition we set the output time resolution at which gridded normal and max outputs are saved in *sfincs_map.nc* using `dtout` and `dtmaxout`, and the time resolution at which timeseries outputs are saved in *sfincs_his.nc* `dthisout`. Note that this is not the computational time step which is adaptive and calculated based on the courant number. Finally, you should set a uniform initial water level at all active cells `zsini`. Be cautious to not set this value too high to avoid initializing the model with flooding. You can set update more model settings in this step, for a full overview see [sfincs docs](https://sfincs.readthedocs.io/en/latest/parameters.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the simulation time in the model config\n",
    "# model_time_config = {\n",
    "#     \"tref\": \"YYYYMMDD hhmmss\", #FILL IN THE REFERENCE TIME (can be any date)\n",
    "#     \"tstart\": \"YYYYMMDD hhmmss\", #FILL IN THE START TIME OF THE SIMULATION\n",
    "#     \"tstop\": \"YYYYMMDD hhmmss\", #FILL IN THE END TIME OF THE SIMULATION\n",
    "#     \"dtout\": ..., # [sec] FILL IN THE TIMESTEP OF THE MAP OUTPUT\n",
    "#     \"dtmaxout\": ...., # [sec] FILL IN THE TIMESTEP OF THE MAXIMUM MAP OUTPUT\n",
    "#     \"dthisout\" : ..., # [sec] FILL IN THE TIMESTEP OF THE SCALAR OUTPUT\n",
    "#     \"zsini\": ..., # [m] FILL IN THE INITIAL WATERLEVEL\n",
    "# }\n",
    "\n",
    "sf.setup_config(**model_time_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water level forcing\n",
    "\n",
    "For the forcing of the water levels at the boundary we use the Global Tide and Surge Model (GTSM). This includes hourly waterlevels at predetermined points. \n",
    "To get the waterlevels at our boundary we interpolate these points to our boundary when we read in the data. \n",
    "\n",
    "Check the `gtsm_locations` and `gtsm_timeseries` files. You can find the file locations in the data catalog.\n",
    "Note that the index attribute of the locations matches with the column names of the timeseries file. This is important for HydroMT to know which timeseries belongs to which location!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to locations and timeseriesa\n",
    "sf.setup_waterlevel_forcing(\n",
    "    locations=\"gtsm_locations\",\n",
    "    timeseries=\"gtsm_timeseries\",\n",
    "    merge=False,  # do not merge with existing locations and timeseries\n",
    "    # use a large buffer to include all points if the following error is raised\n",
    "    # ValueError: The gdf_locs index and df_ts columns must be the same\n",
    "    buffer=1e5,  # buffer from model boundary [m]; exclude points outside the buffer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The keys to access the model forcing\n",
    "print(sf.forcing.keys())\n",
    "\n",
    "# Plot the forcing\n",
    "_ = sf.plot_forcing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model summary so far, showing the GTSM points used for the waterlevel forcing\n",
    "_ = sf.plot_basemap(variable=\"dep\", bmap=\"sat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "a) For how long are you running the simulation?\n",
    "\n",
    "b) How many waterlevel points are used to force the model?\n",
    "\n",
    "c) Which cells are used to force the model with waterlevels? And how are the waterlevels calculated for these cells? (hint: look at the [online documentation](https://sfincs.readthedocs.io/en/stable/input_forcing.html#water-levels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in your answers:\n",
    "\n",
    "a)\n",
    "\n",
    "b)\n",
    "\n",
    "c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 7:** Observation points and lines (BONUS)\n",
    "\n",
    "The final output of the model will generally not be stored with the same temporal resolution the model uses during calculations to keep the output size in check. We can however specify some points and lines, called observation points and lines for which the model outputs are tracked with the higher temporal resolution. Observation points track the water level, while observation lines track the flow volumes passing through that line. These timeseries outputs will be saved in *sfincs_his.nc*\n",
    "\n",
    "The geometry of the observation points and lines are  provided as geojson files. In our exercise we will only add observation points.\n",
    "Create your own geojson by going to http://geojson.io and create observation points in SFINCS. \n",
    "To do so we use the `setup_observation_points` function, calling the geojson that you made.\n",
    "\n",
    "For more information about this function the [docs](https://deltares.github.io/hydromt_sfincs/stable/_generated/hydromt_sfincs.SfincsModel.setup_observation_points.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to observation points & lines geometries\n",
    "# obs_points_fn = Path(r'../model_domain/YOUR_OBS_POINTS_GEOJSON')\n",
    "\n",
    "# Setup observation. merge argument handles whether to override or not\n",
    "sf.setup_observation_points(locations=obs_points_fn, merge=False)\n",
    "\n",
    "# Print the keys to access the observation geometries\n",
    "sf.geoms.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we plot a summary of our model. This shows the boundary used as waterlevel, the points in the GTSM data used for the waterlevel forcing, and the observation points and lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sf.plot_basemap(variable=\"dep\", bmap=\"sat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 8:** Save model\n",
    "\n",
    "Before running the model you need to save it. You can also update and finetune it later by reading it back in append mode. Fill in the cell below to save your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE YOUR MODEL:\n",
    "sf.write()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model will create a standard folder structure to be used when reading a model in. \n",
    "Note that the files in the GIS folder are not used by the model, but are useful for visualisation purposes.\n",
    "This folder structure can be inspected with the code below or by looking at the folder structure in your file explorer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_directory_tree(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        level = root.replace(directory, \"\").count(os.sep)\n",
    "        indent = \" \" * 2 * (level)\n",
    "        print(\"{}{}/\".format(indent, os.path.basename(root)))\n",
    "        subindent = \" \" * 2 * (level + 1)\n",
    "        for f in files:\n",
    "            print(f\"{subindent}+ {f}\")\n",
    "\n",
    "\n",
    "print_directory_tree(sf.root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a zip archive of the model\n",
    "\n",
    "Note this can be used to submit your model on canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: the depfile and manningfile are not written to disk if a subgrid table is present, you may ignore this warning\n",
    "\n",
    "create_sfincs_model_archive(\n",
    "    sfincs_inp=Path(sf.root, \"sfincs.inp\"),\n",
    "    zip_filename=Path(sf.root, \"sfincs_model.zip\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 9:** Run your model\n",
    "We have now set up our own SFINCS model for Charleston, well done! We are now ready to run the model. \n",
    "For more infor see notebook `1_run_your_first_model.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE you need to download the SFINCS executable first (see first notebook) and update the path below\n",
    "# sfincs_exe = Path(\"../../00_software\", \"SFINCS_v2.1.1\", \"sfincs.exe\")\n",
    "\n",
    "run_sfincs(\n",
    "    Path(root_folder, \"sfincs.inp\"),  # path to the SFINCS model root folder\n",
    "    run_method=\"exe\",  # run SFINCS using the executable, other options are \"docker\" or \"singularity\"\n",
    "    sfincs_exe=sfincs_exe,  # path to the sfincs executable if you want to run SFINCS on windows\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 10:** Inspecting the results: floodmap\n",
    "Inspect the results of the model run by plotting the maximum water depths on a map. \n",
    "In order to do so you should first read the results of the model (*sf.read_results()*). \n",
    "After this you can access the results by using the results attribute: *sf.results*.\n",
    "The results you can plot using matplotlib.\n",
    "\n",
    "*Tip: Print all available result keys by typing `print(sf.results.keys())`*  \n",
    "*Tip:* You can also plot the results on top of the SFINCS basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hmax is computed by SFINCS and read-in from the sfincs_map.nc file\n",
    "sf.read_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the subgrid resolution topography to downscale the maximum water level to water depth at the subgrid resolution\n",
    "# First, we read the subgrid resolution topography and check if the file exists\n",
    "dep_subgrid_file = Path(root_folder, \"subgrid\", \"dep_subgrid.tif\")  \n",
    "dep_subgrid = hydromt.open_raster(dep_subgrid_file, nodata=np.nan) # elevation at subgrid resolution\n",
    "\n",
    "# calculate the maximum water depth (hmax) as the difference between \n",
    "# the maximum water level (zsmax) and the elevation (dep)\n",
    "zsmax = sf.results[\"zsmax\"].max(dim=\"timemax\") # maximum water level\n",
    "zsmax_subgrid = zsmax.raster.reproject_like(dep_subgrid, method=\"nearest\")  # reproject to subgrid resolution\n",
    "hmax_subgrid = np.maximum(0, zsmax_subgrid - dep_subgrid).round(2).astype(np.float32) # maximum water depth\n",
    "# Here, we assume that all areas with a negative depth are permanent water bodies\n",
    "# This is a strong simplification. It is better to use a more sophisticated approach\n",
    "# to identify permanent water bodies, e.g. based on a water mask or a \"tide-only\" simulation.\n",
    "permament_water = dep_subgrid < 0 \n",
    "hmax_subgrid = hmax_subgrid.where(~permament_water, np.nan) # mask areas with permanent water\n",
    "# update (geospatial) metadata\n",
    "hmax_subgrid.raster.set_crs(dep_subgrid.raster.crs)\n",
    "hmax_subgrid.raster.set_nodata(np.nan)\n",
    "hmax_subgrid.name = \"max water depth\"\n",
    "hmax_subgrid.attrs[\"units\"] = \"m\"\n",
    "\n",
    "fig, ax = sf.plot_basemap(\n",
    "    fn_out=\"hmax.png\",  # save figure to mod.root/figs/hmax.png\n",
    "    variable=hmax_subgrid,\n",
    "    plot_bounds=False,\n",
    "    bmap=\"sat\",\n",
    "    zoomlevel=12,\n",
    "    figsize=(11, 7),\n",
    "    vmin=0,  # set minimum value for colorbar\n",
    "    vmax=3,  # set maximum value for colorbar\n",
    "    cmap=\"BuPu\",\n",
    ")\n",
    "ax.set_title(\"SFINCS maximum water depth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a geotiff file\n",
    "# round to 2 decimals to reduce file size\n",
    "\n",
    "hmax_subgrid.raster.set_nodata(np.nan)\n",
    "hmax_subgrid.round(2).raster.to_raster(\n",
    "    Path(sf.root, \"hmax.tif\"),\n",
    "    compress=\"lzw\",\n",
    "    overwrite=True,\n",
    "    dtype=\"float32\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "6a) Approximately how far inland does the coastal flood reach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in your answers:\n",
    "\n",
    "6a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **What's Next:** Updating your model boundary conditions\n",
    "\n",
    "Well done, you created your own SFINCS model! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "integrated-modelling-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
