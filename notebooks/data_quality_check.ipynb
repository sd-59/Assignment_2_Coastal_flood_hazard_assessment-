{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c4430aa",
   "metadata": {},
   "source": [
    "# Check the quality of the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a7eab0",
   "metadata": {},
   "source": [
    "This notebook can be used to check the quality of all the input data used in the SFINCS model. The validity of the model results can be derived from these insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dae70d5",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b2f2874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# package import\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import geopandas as gpd\n",
    "import hydromt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hydromt.log import setuplog\n",
    "from hydromt_sfincs import SfincsModel\n",
    "from rasterio.plot import show\n",
    "\n",
    "# local script imports\n",
    "from sfincs_utils import run_sfincs, create_sfincs_model_archive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78d2e4c",
   "metadata": {},
   "source": [
    "#### Read all input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e35fe8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gauging locations read\n",
      "Gauging timeseries read\n",
      "Gebco data read\n",
      "Landcover data read\n",
      "Landcover mapping read\n",
      "OSM land areas read\n",
      "DEM data read\n",
      "Model domain read\n",
      "Observation points read\n",
      "Waterlevel mask read\n"
     ]
    }
   ],
   "source": [
    "gauging_locations = gpd.read_file(\"../data/gtsm_codec_reanalysis_hourly_v1/gauging_location.geojson\").to_crs(epsg=4326)\n",
    "print(\"Gauging locations read\")\n",
    "gauging_timeseries = pd.read_csv(\"../data/gtsm_codec_reanalysis_hourly_v1/validationtimeseries.csv\")\n",
    "print(\"Gauging timeseries read\")\n",
    "with rasterio.open('../data/gebco.tif') as src:\n",
    "    gebco_data = src.read(1)\n",
    "    gebco_nodata = src.nodata\n",
    "    gebco_clean_data = gebco_data[gebco_data != gebco_nodata]\n",
    "    gebco_mean, gebco_std = np.mean(gebco_clean_data), np.std(gebco_clean_data)\n",
    "print(\"Gebco data read\")\n",
    "with rasterio.open('../data/MRLC_landcover.tiff') as src:\n",
    "    landcover_data = src.read(1)\n",
    "    landcover_nodata = src.nodata\n",
    "    landcover_clean_data = landcover_data[landcover_data != landcover_nodata]\n",
    "    landcover_mean, landcover_std = np.mean(landcover_clean_data), np.std(landcover_clean_data)\n",
    "print(\"Landcover data read\")\n",
    "landcover_mapping = pd.read_csv(\"../data/MRLC_landcover_mapping.csv\")\n",
    "print(\"Landcover mapping read\")\n",
    "osm_land_areas = gpd.read_file(\"../data/osm_landareas.gpkg\").to_crs(epsg=4326)\n",
    "print(\"OSM land areas read\")\n",
    "with rasterio.open('../data/topography_Savannah_10m.tif') as src:\n",
    "    DEM_3D_10m_data = src.read(1)\n",
    "    DEM_3D_10m_nodata = src.nodata\n",
    "    DEM_3D_10m_clean_data = DEM_3D_10m_data[DEM_3D_10m_data != DEM_3D_10m_nodata]\n",
    "    DEM_3D_10m_mean, DEM_3D_10m_std = np.mean(DEM_3D_10m_clean_data), np.std(DEM_3D_10m_clean_data)\n",
    "print(\"DEM data read\")\n",
    "# with rasterio.open('../data/topography_Savannah_CoNED_G.tiff') as src:\n",
    "#     CoNED_G_data = src.read(1)\n",
    "#     CoNED_G_nodata = src.nodata\n",
    "#     CoNED_G_clean_data = CoNED_G_data[CoNED_G_data != CoNED_G_nodata]\n",
    "#     CoNED_G_mean, CoNED_G_std = np.mean(CoNED_G_clean_data), np.std(CoNED_G_clean_data)\n",
    "# print(\"Georga DEM data read\")\n",
    "# with rasterio.open('../data/topography_Savannah_CoNED_SC.tiff') as src:\n",
    "#     CoNED_SC_data = src.read(1)\n",
    "#     CoNED_SC_nodata = src.nodata\n",
    "#     CoNED_SC_clean_data = CoNED_SC_data[CoNED_SC_data != CoNED_SC_nodata]\n",
    "#     CoNED_SC_mean, CoNED_SC_std = np.mean(CoNED_SC_clean_data), np.std(CoNED_SC_clean_data)\n",
    "# print(\"South Carolina DEM data read\")\n",
    "model_domain = gpd.read_file(\"../model_domain/model_domain_savannah.geojson\").to_crs(epsg=4326)\n",
    "print(\"Model domain read\")\n",
    "obs_points = gpd.read_file(\"../model_domain/obs_points_savannah.geojson\").to_crs(epsg=4326)\n",
    "print(\"Observation points read\")\n",
    "wl_mask = gpd.read_file(\"../model_domain/waterlevel_mask_savannah.geojson\").to_crs(epsg=4326)\n",
    "print(\"Waterlevel mask read\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72edd8c",
   "metadata": {},
   "source": [
    "#### Visualise inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65064942",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date and time '",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanne\\integrated-modelling-in-hydrology\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'date and time '",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     35\u001b[39m     outliers = df[(df[\u001b[33m'\u001b[39m\u001b[33m (m)\u001b[39m\u001b[33m'\u001b[39m] < bottom_limit) | (df[\u001b[33m'\u001b[39m\u001b[33m (m)\u001b[39m\u001b[33m'\u001b[39m] > upper_limit)]\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df_reindexed, nans, bottom_limit, upper_limit\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m gauging_reindexed, gauging_nans, gauging_bot, gauging_up = \u001b[43mfind_nans_and_outliers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgauging_timeseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate and time \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m (m)\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m aantal_rijen = \u001b[32m12\u001b[39m\n\u001b[32m     42\u001b[39m fig_height = aantal_rijen * \u001b[32m4\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mfind_nans_and_outliers\u001b[39m\u001b[34m(df_in, date_col, val_col)\u001b[39m\n\u001b[32m     18\u001b[39m df[date_col] = pd.to_datetime(df[date_col])\n\u001b[32m     19\u001b[39m df = df.set_index(date_col)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m freq = pd.infer_freq(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdate_col\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     21\u001b[39m full_date_range = pd.date_range(start=df[date_col].min(), \n\u001b[32m     22\u001b[39m                                 end=df[date_col].max(), \n\u001b[32m     23\u001b[39m                                 freq=freq)\n\u001b[32m     24\u001b[39m df_reindexed = df.reindex(full_date_range)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanne\\integrated-modelling-in-hydrology\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanne\\integrated-modelling-in-hydrology\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'date and time '"
     ]
    }
   ],
   "source": [
    "gebco_missing_mask = (gebco_data == gebco_nodata)\n",
    "gebco_outlier_mask = (np.abs(gebco_data - gebco_mean) > 3 * gebco_std) & (gebco_data != gebco_nodata)\n",
    "\n",
    "landcover_missing_mask = (landcover_data == landcover_nodata)\n",
    "landcover_outlier_mask = (np.abs(landcover_data - landcover_mean) > 3 * landcover_std) & (landcover_data != landcover_nodata)\n",
    "\n",
    "DEM_3D_10m_missing_mask = (DEM_3D_10m_data == DEM_3D_10m_nodata)\n",
    "DEM_3D_10m_outlier_mask = (np.abs(DEM_3D_10m_data - DEM_3D_10m_mean) > 3 * DEM_3D_10m_std) & (DEM_3D_10m_data != DEM_3D_10m_nodata)\n",
    "\n",
    "# CoNED_G_missing_mask = (CoNED_G_data == CoNED_G_nodata)\n",
    "# CoNED_G_outlier_mask = (np.abs(CoNED_G_data - CoNED_G_mean) > 3 * CoNED_G_std) & (CoNED_G_data != CoNED_G_nodata)\n",
    "\n",
    "# CoNED_SC_missing_mask = (CoNED_SC_data == CoNED_SC_nodata)\n",
    "# CoNED_SC_outlier_mask = (np.abs(CoNED_SC_data - CoNED_SC_mean) > 3 * CoNED_SC_std) & (CoNED_SC_data != CoNED_SC_nodata)\n",
    "\n",
    "def find_nans_and_outliers(df_in, date_col, val_col):\n",
    "    df = df_in.copy()\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df = df.set_index(date_col)\n",
    "    freq = pd.infer_freq(df[date_col])\n",
    "    full_date_range = pd.date_range(start=df[date_col].min(), \n",
    "                                    end=df[date_col].max(), \n",
    "                                    freq=freq)\n",
    "    df_reindexed = df.reindex(full_date_range)\n",
    "\n",
    "    nans = df_reindexed[df_reindexed[val_col].isna()]\n",
    "    missing_dates = full_date_range.difference(df[date_col])\n",
    "\n",
    "    Q1 = df[val_col].quantile(0.25)\n",
    "    Q3 = df[val_col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    bottom_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = df[(df[' (m)'] < bottom_limit) | (df[' (m)'] > upper_limit)]\n",
    "\n",
    "    return df_reindexed, nans, bottom_limit, upper_limit\n",
    "\n",
    "gauging_reindexed, gauging_nans, gauging_bot, gauging_up = find_nans_and_outliers(gauging_timeseries, \"date and time \", \" (m)\")\n",
    "\n",
    "aantal_rijen = 12\n",
    "fig_height = aantal_rijen * 4\n",
    "\n",
    "fig, ax = plt.subplots(aantal_rijen, 3, figsize=(20, fig_height), constrained_layout=True)\n",
    "\n",
    "ax[0,0].set_title(\"Gebco\")\n",
    "ax[0,0].imshow(gebco_data, cmap='viridis')\n",
    "ax[0,1].imshow(gebco_missing_mask)\n",
    "ax[0,2].imshow(gebco_outlier_mask)\n",
    "\n",
    "ax[1,0].imshow(landcover_data, cmap='viridis')\n",
    "ax[1,1].imshow(landcover_missing_mask)\n",
    "ax[1,2].imshow(landcover_outlier_mask)\n",
    "\n",
    "ax[2,0].imshow(DEM_3D_10m_data, cmap='viridis')\n",
    "ax[2,1].imshow(DEM_3D_10m_missing_mask)\n",
    "ax[2,2].imshow(DEM_3D_10m_outlier_mask)\n",
    "\n",
    "# ax[3,0].imshow(CoNED_G_data, cmap='viridis')\n",
    "# ax[3,1].imshow(CoNED_G_missing_mask)\n",
    "# ax[3,2].imshow(CoNED_G_outlier_mask)\n",
    "\n",
    "# ax[4,0].imshow(CoNED_SC_data, cmap='viridis')\n",
    "# ax[4,1].imshow(CoNED_SC_missing_mask)\n",
    "# ax[4,2].imshow(CoNED_SC_outlier_mask)\n",
    "\n",
    "ax[3,0].plot(gauging_reindexed[\"date and time \"], gauging_reindexed[\" (m)\"], label=\"Waterlevel\")\n",
    "ax[3,0].scatter(gauging_nans.index, (gauging_reindexed[\" (m)\"].min() * len(gauging_nans)), color=\"red\", label=\"Holes in dataset, s=20, zorder=5\")\n",
    "ax[3,0].axhline(gauging_bot, color=\"gray\")\n",
    "ax[3,0].axhline(gauging_up, color=\"gray\")\n",
    "ax[3,0].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26686490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date and time ', ' (m)'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauging_timeseries.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "integrated-modelling-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
